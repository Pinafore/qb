{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from qanta.datasets.quiz_bowl import QuestionDatabase\n",
    "from qanta.util.constants import GUESSER_TRAIN_FOLD, GUESSER_DEV_FOLD\n",
    "from qanta.guesser.rnn_entity import RnnEntityGuesser, BatchedDataset,\\\n",
    "    clean_question, repackage_hidden\n",
    "from qanta.guesser.nn import convert_text_to_embeddings_indices\n",
    "from qanta.preprocess import tokenize_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guesser = RnnEntityGuesser.load('output/guesser/qanta.guesser.rnn_entity.RnnEntityGuesser/')\n",
    "guesser.model = guesser.model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RnnEntityModel(\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (word_embeddings): Embedding(139580, 300, padding_idx=0)\n",
       "  (rnn): WeightDrop(\n",
       "    (module): GRU(300, 1000, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "  )\n",
       "  (classification_layer): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=8297)\n",
       "    (1): BatchNorm1d(8297, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): Dropout(p=0.15)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_grads = {}\n",
    "\n",
    "def extract_grad_hook(name):\n",
    "    def hook(grad):\n",
    "        extracted_grads[name] = grad\n",
    "    return hook\n",
    "\n",
    "guesser.model = guesser.model.cuda()\n",
    "guesser.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = QuestionDatabase().all_questions().values()\n",
    "questions = [q for q in questions if q.fold == GUESSER_DEV_FOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stuff(question_list):\n",
    "    x_test_tokens = [x for x in question_list]\n",
    "    y_test = np.zeros(len(question_list))\n",
    "    dataset = BatchedDataset(\n",
    "        guesser.batch_size, guesser.multi_embedding_lookup, guesser.rel_position_vocab, guesser.rel_position_lookup,\n",
    "        x_test_tokens, y_test,\n",
    "        truncate=False, shuffle=False, train=False\n",
    "    )\n",
    "\n",
    "    grads = []\n",
    "    outputs = []\n",
    "    losses = []\n",
    "    hidden = guesser.model.init_hidden(guesser.batch_size)\n",
    "\n",
    "    for b in range(len(dataset.t_x_w_batches)):\n",
    "        t_x_w_batch = Variable(dataset.t_x_w_batches[b])\n",
    "        t_x_pos_batch = Variable(dataset.t_x_pos_batches[b])\n",
    "        t_x_iob_batch = Variable(dataset.t_x_iob_batches[b])\n",
    "        t_x_type_batch = Variable(dataset.t_x_type_batches[b])\n",
    "        t_x_mention_batch = Variable(dataset.t_x_mention_batches[b])\n",
    "\n",
    "        length_batch = dataset.length_batches[b]\n",
    "        sort_batch = dataset.sort_batches[b]\n",
    "\n",
    "        hidden = guesser.model.init_hidden(len(length_batch))\n",
    "        \n",
    "#         if len(length_batch) != guesser.batch_size:\n",
    "#             # This could happen for the last batch which is shorter than batch_size\n",
    "#             hidden = guesser.model.init_hidden(len(length_batch))\n",
    "#         else:\n",
    "#             hidden = repackage_hidden(hidden, reset=True)\n",
    "\n",
    "        guesser.model.eval()\n",
    "        out, hidden = guesser.model(\n",
    "            t_x_w_batch, t_x_pos_batch, t_x_iob_batch, t_x_type_batch, t_x_mention_batch,\n",
    "            length_batch, hidden, extract_grad_hook('embed')\n",
    "        )\n",
    "        scores, preds = torch.max(out, 1) # take gradient w.r.t top guess\n",
    "        outputs.append(out.data)\n",
    "\n",
    "        guesser.model.zero_grad()\n",
    "        loss = criterion(out, preds)\n",
    "        losses.append(loss.data)\n",
    "        \n",
    "        loss.sum().backward()\n",
    "        batch_size, length = t_x_w_batch.size()\n",
    "        embed_grad = extracted_grads['embed'].contiguous()\n",
    "        embed = guesser.model.word_embeddings(t_x_w_batch)\n",
    "        onehot_grad = embed.view(-1) * embed_grad.view(-1)\n",
    "        onehot_grad = onehot_grad.view(batch_size, length, -1).sum(-1)\n",
    "        onehot_grad = onehot_grad.data.cpu().numpy()\n",
    "        grads.append(onehot_grad)\n",
    "    \n",
    "    grads = np.concatenate(grads)\n",
    "    outputs = torch.cat(outputs)\n",
    "    losses = torch.cat(losses)\n",
    "    \n",
    "    return grads, outputs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def greedy_remove(question_list):\n",
    "#     _xs = [list(guesser.nlp(clean_question(x.flatten_text()))) for x in question_list]\n",
    "#     _ys = [x[0][0] for x in guesser.guess(_xs, 10, tokenize=False)]\n",
    "\n",
    "#     removed_indices = [[] for _ in question_list]\n",
    "#     indices = [list(range(len(x))) for x in _xs]\n",
    "#     alive = [True for _ in _xs]\n",
    "    \n",
    "#     xs = list(_xs)\n",
    "        \n",
    "#     while True:\n",
    "#         onehot_grad, out, loss = get_onehot_grad(xs)\n",
    "#         for i, x in enumerate(xs):\n",
    "#             if len(x) == 1:\n",
    "#                 alive[i] = False # stop removing when there is only one token left\n",
    "#             if alive[i]:\n",
    "#                 drop_idx = np.argmax(onehot_grad[i][:len(x)])\n",
    "#                 removed_indices[i].append(indices[i][drop_idx])\n",
    "#                 indices[i] = indices[i][:drop_idx] + indices[i][drop_idx + 1:]\n",
    "#                 x = x[:drop_idx] + x[drop_idx + 1:]\n",
    "#             xs[i] = x\n",
    "\n",
    "#         if sum(alive) == 0:\n",
    "#             break\n",
    "        \n",
    "#         pred = [x[0][0] for x in guesser.guess(xs, 10, tokenize=False)]\n",
    "#         for i, (x, y, z) in enumerate(zip(xs, _ys, pred)):\n",
    "#             if z != y:\n",
    "#                 alive[i] = False\n",
    "#                 removed_indices[i] = removed_indices[i][:-1]\n",
    "#     return removed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_search_remove(question, max_beam_size=10):\n",
    "    original = guesser.guess([question], 10, tokenize=False)[0][0][0]\n",
    "    \n",
    "    removed_indices = [[]]\n",
    "    indices = [list(range(len(question)))]\n",
    "    \n",
    "    xs = [list(question)]\n",
    "    \n",
    "    while True:        \n",
    "        print(len(xs[0]), end=' ')\n",
    "        \n",
    "        if len(xs) == 0:\n",
    "            break\n",
    "        \n",
    "        assert len(removed_indices) == len(xs)\n",
    "        assert len(indices) == len(xs)\n",
    "        \n",
    "        onehot_grad, _, _ = get_stuff(xs)\n",
    "        new_xs = []\n",
    "        new_removed = []\n",
    "        new_indices = []\n",
    "\n",
    "        for i, x in enumerate(xs):\n",
    "            order = np.argsort(onehot_grad[i][:len(x)])[:max_beam_size]\n",
    "            for k in order:\n",
    "                new_xs.append(x[:k] + x[k + 1:])\n",
    "                new_removed.append(removed_indices[i] + [indices[i][k]])\n",
    "                new_indices.append(indices[i][:k] + indices[i][k + 1:])\n",
    "        \n",
    "        guesses = [x[0] for x in guesser.guess(new_xs, 10, tokenize=False)]\n",
    "        # print(sum(g == original for g, s in guesses))\n",
    "        \n",
    "        indices = [(i, (g, s)) for i, (g, s) in enumerate(guesses) if g == original]\n",
    "        indices = [i for i, _ in sorted(indices, key=lambda x: x[1][1])[:max_beam_size]]\n",
    "        if len(indices) == 0:\n",
    "            return removed_indices\n",
    "        \n",
    "        xs = [new_xs[i] for i in indices]\n",
    "        removed_indices = [new_removed[i] for i in indices]\n",
    "        indices = [new_indices[i] for i in indices]\n",
    "        # guesses = [x[0][0] for x in guesser.guess(xs, 10, tokenize=False)]\n",
    "        # print(sum(x == original for x in guesses))\n",
    "        # print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 +++\n",
      "74 73 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch0/shifeng/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py:325: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/scratch0/shifeng/qb/qanta/guesser/rnn_entity.py:687: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 \n",
      "1 +++\n",
      "53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 \n",
      "2 +++\n",
      "77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 \n",
      "3 +++\n",
      "74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 \n",
      "4 +++\n",
      "43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 \n",
      "5 +++\n",
      "69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 \n",
      "6 +++\n",
      "53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 \n",
      "7 +++\n",
      "60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 \n",
      "8 +++\n",
      "78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 "
     ]
    }
   ],
   "source": [
    "removed_indices = []\n",
    "for i, q in enumerate(questions[:30]):\n",
    "    print(i, '+++')\n",
    "    q = list(guesser.nlp(clean_question(q.flatten_text())))\n",
    "    removed_indices.append(beam_search_remove(q, 20)[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch0/shifeng/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py:325: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/scratch0/shifeng/qb/qanta/guesser/rnn_entity.py:687: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question\n",
      "he rescues a hindu widow from ritual burning and takes her as his bride . but first he must convince detective fix that he is not a bank robber . this is after he has crossed three continents and two oceans on trains , steamers , and an elephant , with his valet passepartout . for 10 points name this well - traveled jules verne character who circumnavigated the globe in 1920 hours .\n",
      "\n",
      "Modified Question\n",
      "fix\n",
      "\n",
      "Original Guesses\n",
      "Around_the_World_in_Eighty_Days 0.167796\n",
      "\n",
      "Modified Guesses\n",
      "Around_the_World_in_Eighty_Days 0.0889402\n",
      "\n",
      "Original Question\n",
      "some scholars identify him with the \" two horned one \" mentioned in the koran . he defeated darius iii at issus in 333 bc , ten years before his own sudden death at age 33 . for 10 points name this macedonian king who founded a namesake city in northern egypt .\n",
      "\n",
      "Modified Question\n",
      "horned\n",
      "\n",
      "Original Guesses\n",
      "Alexander_the_Great 0.997825\n",
      "\n",
      "Modified Guesses\n",
      "Alexander_the_Great 0.029787\n",
      "\n",
      "Original Question\n",
      "they were not the punic wars , but there were three of them and the second was the most famous . it lasted seven years , costing 2000 u.s. dead and sixty million dollars , and was the costliest war in the u.s. between the war of 1812 and the mexican war . for 10 points name this war in which one side could use natural barriers , such as the everglades , to its advantage .\n",
      "\n",
      "Modified Question\n",
      "wars them costing mexican everglades its\n",
      "\n",
      "Original Guesses\n",
      "Seminole_Wars 0.109965\n",
      "\n",
      "Modified Guesses\n",
      "Seminole_Wars 0.0324321\n",
      "\n",
      "Original Question\n",
      "before his medical internship in 1921 , this man traveled to the soviet union to help fight a series of epidemics , but was persuaded by lenin to use his business knowledge to help the country instead . he then abandoned medicine , helped start several businesses in the ussr , and eventually bought the occidental petroleum corporation . for 10 points name this executive who helped spur greater east - west ties .\n",
      "\n",
      "Modified Question\n",
      "this soviet epidemics occidental\n",
      "\n",
      "Original Guesses\n",
      "Joseph_Stalin 0.358378\n",
      "\n",
      "Modified Guesses\n",
      "Joseph_Stalin 0.0173632\n",
      "\n",
      "Original Question\n",
      "iceland has many hot springs and volcanoes , but that 's not why its mean daily temperature is nine degrees higher than might be expected at that latitude . for 10 points what warm - water atlantic current moderates iceland 's climate ?\n",
      "\n",
      "Modified Question\n",
      "water current\n",
      "\n",
      "Original Guesses\n",
      "Gulf_Stream 0.374915\n",
      "\n",
      "Modified Guesses\n",
      "Gulf_Stream 0.0620813\n",
      "\n",
      "Original Question\n",
      "of the nine defendants , only matthew killroy and hugh montgomery were found guilty , and then only of manslaughter . they were granted benefit of clergy because both could read , and were branded on the thumb as punishment . for 10 points of what { december 1770 } crime were these soldiers accused , which resulted in the deaths of five men , including crispus attucks ?\n",
      "\n",
      "Modified Question\n",
      "manslaughter crispus\n",
      "\n",
      "Original Guesses\n",
      "Boston_Massacre 0.997813\n",
      "\n",
      "Modified Guesses\n",
      "Boston_Massacre 0.137411\n",
      "\n",
      "Original Question\n",
      "named for the teutonic goddess of the dawn , it was set in 325 ad by the council of nicaea as being the first sunday after the first full moon after the vernal equinox . for 10 points name this holiday , further restricted as occurring between march 22 and april 25 .\n",
      "\n",
      "Modified Question\n",
      "sunday vernal\n",
      "\n",
      "Original Guesses\n",
      "Easter 0.0532345\n",
      "\n",
      "Modified Guesses\n",
      "Easter 0.0441006\n",
      "\n",
      "Original Question\n",
      "he died in 1542 at the age of 42 . earlier he had been with pizarro in peru and was named governor of cuba . in 1539 he set out to conquer florida , and explored much of the american south . for 10 points name this spanish explorer who saw the mississippi river and was buried in it .\n",
      "\n",
      "Modified Question\n",
      "1542 river\n",
      "\n",
      "Original Guesses\n",
      "Hernando_de_Soto 0.99998\n",
      "\n",
      "Modified Guesses\n",
      "Hernando_de_Soto 0.0326749\n",
      "\n",
      "Original Question\n",
      "in 1859 , lescarbault discovered a black dot in rapid transit across the solar disk . urbain leverrier showed that it would explain the anomalous perihelion advance of mercury . unfortunately , it was never seen again , and the observations of mercury were later explained by general relativity . for 10 points name this one - time tenth member of the solar system which lent its name to the home of star trek 's mr. spock .\n",
      "\n",
      "Modified Question\n",
      "lescarbault\n",
      "\n",
      "Original Guesses\n",
      "Vulcan 0.994024\n",
      "\n",
      "Modified Guesses\n",
      "Vulcan 0.0759859\n",
      "\n",
      "Original Question\n",
      "on october 17 , 1978 , president jimmy carter signed a bill restoring u.s. citizenship to this man , a mississippi senator from 1847 to 1851 and 1857 to 1861 . for 10 points name this secretary of war under franklin pierce and , from 1861 to 1865 , president of the confederacy .\n",
      "\n",
      "Modified Question\n",
      "mississippi\n",
      "\n",
      "Original Guesses\n",
      "Jefferson_Davis 0.929725\n",
      "\n",
      "Modified Guesses\n",
      "Jefferson_Davis 0.1011\n",
      "\n",
      "Original Question\n",
      "lured to london in 1774 by benjamin west , he stayed until his death 41 years later . nevertheless , he is considered a very american painter , with portraits of samuel adams , john hancock , and john adams to his credit . for 10 points name this boston - born artist who also did portraits of lord cornwallis , as well as \" the death of lord chatham \" and \" the victory of lord duncan . \"\n",
      "\n",
      "Modified Question\n",
      "chatham duncan\n",
      "\n",
      "Original Guesses\n",
      "John_Singleton_Copley 0.460304\n",
      "\n",
      "Modified Guesses\n",
      "John_Singleton_Copley 0.0892111\n",
      "\n",
      "Original Question\n",
      "named from proverbs 11:29 , a 1995 revival at the national actors theater starred charles durning as matthew harrison brady and as george c. scott as henry drummond in for 10 points what 1955 play by jerome lawrence and robert edwin lee , modeled on the 1925 { scopes trial } ?\n",
      "\n",
      "Modified Question\n",
      "matthew edwin lee\n",
      "\n",
      "Original Guesses\n",
      "Inherit_the_Wind 0.999907\n",
      "\n",
      "Modified Guesses\n",
      "Inherit_the_Wind 0.0829706\n",
      "\n",
      "Original Question\n",
      "the title character and friends seize the acropolis to cut off the athenian treasury . the seizure is part of a plot by the greek women to end the peloponnesian war by refusing to have intercourse with their husbands until a treaty is signed in for 10 points which comedy by aristophanes ?\n",
      "\n",
      "Modified Question\n",
      "cut treasury husbands comedy\n",
      "\n",
      "Original Guesses\n",
      "Lysistrata 0.999884\n",
      "\n",
      "Modified Guesses\n",
      "Lysistrata 0.0102803\n",
      "\n",
      "Original Question\n",
      "according to the oxford english dictionary , the words \" fancy - free , \" \" eventful , \" \" dislocate , \" \" premeditated , \" \" lackluster , \" \" barefaced , \" \" dwindle , \" \" submerged , \" and \" assassination \" all debuted in print for 10 points in the works of what member of lord chamberlain 's men and the blackfriars theater , born in stratford - on - avon ?\n",
      "\n",
      "Modified Question\n",
      "avon\n",
      "\n",
      "Original Guesses\n",
      "William_Shakespeare 0.8939\n",
      "\n",
      "Modified Guesses\n",
      "William_Shakespeare 0.358269\n",
      "\n",
      "Original Question\n",
      "it was followed by a wind in the door and a swiftly tilting planet . this 1962 novel introduces the murry children , who engage in a cosmic battle against \" it , \" a great evil brain that despises individuality . for 10 points name this newbery award winner by madeleine l'engle .\n",
      "\n",
      "Modified Question\n",
      "children brain despises\n",
      "\n",
      "Original Guesses\n",
      "A_Wrinkle_in_Time 0.999886\n",
      "\n",
      "Modified Guesses\n",
      "A_Wrinkle_in_Time 0.0257268\n",
      "\n",
      "Original Question\n",
      "his 1941 short story \" nightfall \" is considered by many to be the finest science - fiction story ever written . he was born in russia in 1920 , but was brought to the u.s. at the age of three . for 10 points name this biochemist who also wrote the foundation series of novels .\n",
      "\n",
      "Modified Question\n",
      "1941 finest science\n",
      "\n",
      "Original Guesses\n",
      "Isaac_Asimov 0.993222\n",
      "\n",
      "Modified Guesses\n",
      "Isaac_Asimov 0.0249923\n",
      "\n",
      "Original Question\n",
      "a student of anthropologist bronislaw malinowski , he analyzed his own kikuyu culture in 1938 's \" facing mount kenya . \" imprisoned by the british for involvement in the mau mau uprising , he was released in 1961 . for 10 points name this first prime minister and president of kenya .\n",
      "\n",
      "Modified Question\n",
      "malinowski analyzed 1961\n",
      "\n",
      "Original Guesses\n",
      "Jomo_Kenyatta 0.974655\n",
      "\n",
      "Modified Guesses\n",
      "Jomo_Kenyatta 0.197326\n",
      "\n",
      "Original Question\n",
      "it was adapted to languages such as hattis and hurrian in asia minor , elbaite in syria , and urartian in armenia . the babylonian and assyrian versions each used 300 to 600 arbitrary symbols of for 10 points what method of writing whose name is latin for \" wedge - shaped \" ?\n",
      "\n",
      "Modified Question\n",
      "hattis assyrian symbols\n",
      "\n",
      "Original Guesses\n",
      "Cuneiform_script 0.871469\n",
      "\n",
      "Modified Guesses\n",
      "Cuneiform_script 0.0141538\n",
      "\n",
      "Original Question\n",
      "unlike the canadian provinces of newfoundland , prince edward island , and nova scotia , none of which border any u.s. state , what province for 10 points borders the most states , new york , vermont , new hampshire , and maine ?\n",
      "\n",
      "Modified Question\n",
      "scotia province vermont\n",
      "\n",
      "Original Guesses\n",
      "New_Brunswick 0.386594\n",
      "\n",
      "Modified Guesses\n",
      "New_Brunswick 0.0695869\n",
      "\n",
      "Original Question\n",
      "his collected works fill 143 volumes , and include entoptic colors , on the theory of colors , and the metamorphosis of plants . for 10 points name this german poet and playwright of gotz von berlichingen , clavigo , iphegenia in tauris , and faust .\n",
      "\n",
      "Modified Question\n",
      "colors iphegenia\n",
      "\n",
      "Original Guesses\n",
      "Johann_Wolfgang_von_Goethe 0.999999\n",
      "\n",
      "Modified Guesses\n",
      "Johann_Wolfgang_von_Goethe 0.158643\n",
      "\n",
      "Original Question\n",
      "new york federal district court judge john woolsey ruled : \" although it contains ... many words usually considered dirty , i have not found anything that i consider to be dirt for dirt 's sake . \" for 10 points name this 1922 novel featuring a jewish advertising canvasser and which focuses on the events of one day , written by james joyce .\n",
      "\n",
      "Modified Question\n",
      "... novel\n",
      "\n",
      "Original Guesses\n",
      "Ulysses_(novel) 0.998024\n",
      "\n",
      "Modified Guesses\n",
      "Ulysses_(novel) 0.0112658\n",
      "\n",
      "Original Question\n",
      "caused by the spirochete borrelia burgdorferi , if caught early , it can be treated with tetracycline . if not treated , the characteristic rash is followed by periodic arthritis , and possibly meningitis . for 10 points name this disease carried by some species of deer tick .\n",
      "\n",
      "Modified Question\n",
      "spirochete deer\n",
      "\n",
      "Original Guesses\n",
      "Lyme_disease 1.0\n",
      "\n",
      "Modified Guesses\n",
      "Lyme_disease 0.580985\n",
      "\n",
      "Original Question\n",
      "art aficionados carlo starnazzi and claudio santori announced in late 1995 that its background is the village of ponte a buriano on the river arno near the tuscan city of arezzo . for 10 points name this da vinci painting , commissioned for francesco del giocondo , that features art 's most famous enigmatic smile .\n",
      "\n",
      "Modified Question\n",
      "enigmatic\n",
      "\n",
      "Original Guesses\n",
      "Mona_Lisa 0.54769\n",
      "\n",
      "Modified Guesses\n",
      "Mona_Lisa 0.103607\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question\n",
      "composed of the harivamsa and 18 parvans , or chapters , it is ascribed to the sage vyasa , and it is a valuable source on the transition from vedic to hindu india . for 10 points name this epic , which tells of a dynastic war between the pandavas and kauravas and features the god krishna .\n",
      "\n",
      "Modified Question\n",
      "harivamsa krishna\n",
      "\n",
      "Original Guesses\n",
      "Mahabharata 0.998199\n",
      "\n",
      "Modified Guesses\n",
      "Mahabharata 0.546011\n",
      "\n",
      "Original Question\n",
      "the subject of the 1994 oscar - winning feature documentary , \" a strong clear vision , \" she was commissioned to sculpt an alabama monument commemorating the civil rights movement . for 10 points name this yale alum , best known for designing the vietnam veterans ' memorial .\n",
      "\n",
      "Modified Question\n",
      "vision rights this designing vietnam\n",
      "\n",
      "Original Guesses\n",
      "Maya_Lin 0.272832\n",
      "\n",
      "Modified Guesses\n",
      "Maya_Lin 0.0149818\n",
      "\n",
      "Original Question\n",
      "massachusetts residents love the trailing arbutus , their state flower . however , this species has another common name , which is more readily associated with the first european inhabitants of the area . for 10 points give the other common name of the massachusetts state flower , shared with the ship which brought the region its most famous immigrants .\n",
      "\n",
      "Modified Question\n",
      "this readily flower ship\n",
      "\n",
      "Original Guesses\n",
      "Mayflower 0.996106\n",
      "\n",
      "Modified Guesses\n",
      "Mayflower 0.0221451\n",
      "\n",
      "Original Question\n",
      "it 's twice as strong under compression than concrete , and a 10-square - centimeter column can support an 11,000 pound elephant . though it burns too readily to be widely used in construction , it lacks the weak spots of conventional wood , and is associated with structures in the tropics . for 10 points name this woody plant whose shoots are commonly found in stir - fry dishes .\n",
      "\n",
      "Modified Question\n",
      "it than concrete 10-square column pound elephant burns widely lacks spots associated with name plant fry\n",
      "\n",
      "Original Guesses\n",
      "El_Niño 0.0263976\n",
      "\n",
      "Modified Guesses\n",
      "El_Niño 0.00791816\n",
      "\n",
      "Original Question\n",
      "the pretext for this war was the protection of christian pilgrims in the holy land , but the real issue concerned russia 's attempt to control the straits of constantinople . for 10 points name this war , fought near the shores of the black sea , which lasted from 1853 to 1856 and which witnessed the famous charge of the light brigade .\n",
      "\n",
      "Modified Question\n",
      "pretext shores charge\n",
      "\n",
      "Original Guesses\n",
      "Crimean_War 0.999949\n",
      "\n",
      "Modified Guesses\n",
      "Crimean_War 0.0105624\n",
      "\n",
      "Original Question\n",
      "the son of princess dechtire and the god lug [ loo ] , in the cattle raid of cooley he single - handedly staves off an invading force from { connaught}. for 10 points name this chief servant of king conor , a key character in the irish { ulster cycle}.\n",
      "\n",
      "Modified Question\n",
      "cooley\n",
      "\n",
      "Original Guesses\n",
      "Cú_Chulainn 0.0318231\n",
      "\n",
      "Modified Guesses\n",
      "Cú_Chulainn 0.611551\n",
      "\n",
      "Original Question\n",
      "the boettcher memorial conservatory , the gates planetarium , loretto heights college , and the former lowry air force base , are all found for 10 points in what city formed at the junction of cherry creek and the south platte river , the most populous in colorado ?\n",
      "\n",
      "Modified Question\n",
      "platte\n",
      "\n",
      "Original Guesses\n",
      "Denver 0.863979\n",
      "\n",
      "Modified Guesses\n",
      "Denver 0.841454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, removed in enumerate(removed_indices):\n",
    "    q = list(guesser.nlp(clean_question(questions[i].flatten_text())))\n",
    "    before_guesses = guesser.guess([q], 10, tokenize=False)[0][0]\n",
    "    qq = [w for i, w in enumerate(q) if i not in removed]\n",
    "    after_guesses = guesser.guess([qq], 10, tokenize=False)[0][0]\n",
    "    \n",
    "    print('Original Question')\n",
    "    print(' '.join([x.lower_ for x in q]))\n",
    "    print()\n",
    "    print('Modified Question')\n",
    "    print(' '.join([x.lower_ for x in qq]))\n",
    "    print()\n",
    "    print('Original Guesses')\n",
    "    print(before_guesses[0], before_guesses[1])\n",
    "    print()\n",
    "    print('Modified Guesses')\n",
    "    print(after_guesses[0], after_guesses[1])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
